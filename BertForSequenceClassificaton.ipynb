{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig, BertForSequenceClassification\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = { \"name\": \"Stanford treebank\",\n",
    "            \"prefix\": \"stanford_treebank\",\n",
    "            \"train_path\": \"data/stanford_treebank/sst_train.csv\",\n",
    "            \"dev_path\": \"data/stanford_treebank/sst_dev.csv\",\n",
    "            \"test_path\": \"data/stanford_treebank/sst_test.csv\",\n",
    "            'classes': ['neg', 'pos']\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    train = pd.read_csv(dataset['train_path'],index_col=0)\n",
    "    dev = pd.read_csv(dataset['dev_path'],index_col=0)\n",
    "    test = pd.read_csv(dataset['test_path'],index_col=0)\n",
    "    return train, dev, test\n",
    "train, dev, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, tokenizer):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for text in data:\n",
    "        tokenized_text = tokenizer.encode_plus(text,\n",
    "                                            max_length=128,\n",
    "                                            add_special_tokens = True,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            padding_side='right',\n",
    "                                            return_attention_mask=True)\n",
    "        input_ids.append(tokenized_text['input_ids'])\n",
    "        attention_mask.append(tokenized_text['attention_mask'])\n",
    "    return torch.tensor(input_ids, dtype=torch.long), torch.tensor(attention_mask, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(df, tokenizer, batch_size=4):\n",
    "    x, y = list(df['text'].values), list(df['classification'].apply(lambda y: dataset['classes'].index(y)))\n",
    "    input_ids, attention_mask = encode(x, tokenizer)\n",
    "    y = torch.tensor(y)\n",
    "    tensor_dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, y)\n",
    "    tensor_randomsampler = torch.utils.data.RandomSampler(tensor_dataset)\n",
    "    tensor_dataloader = torch.utils.data.DataLoader(tensor_dataset, sampler=tensor_randomsampler, batch_size=batch_size)\n",
    "    return tensor_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch, model, optimizer, scheduler, epochs):\n",
    "    model.train()  # Set the mode to training\n",
    "    for e in range(epochs):\n",
    "        for i, batch_tuple in enumerate(batch):\n",
    "            batch_tuple = (t.to(device) for t in batch_tuple)\n",
    "            input_ids, attention_mask, labels = batch_tuple\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits, hidden_states_output, attention_mask_output = outputs\n",
    "            if i % 100 == 0:\n",
    "                print(\"loss - {0}\".format(loss))\n",
    "            model.zero_grad()        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), parameters['max_grad_norm'])\n",
    "            optimizer.step()\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_dev = get_batches(dev, batch_size=1, tokenizer=tokenizer)\n",
    "#batch_train = get_batches(train_data, batch_size=8, tokenizer=tokenizer)\n",
    "#batch_test = get_batches(test, batch_size=1, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_dev = get_batches(dev, batch_size=1, tokenizer=tokenizer)\n",
    "batch_train = get_batches(train, batch_size=8, tokenizer=tokenizer)\n",
    "batch_test = get_batches(test, batch_size=1, tokenizer=tokenizer)\n",
    "\n",
    "epochs=1\n",
    "parameters = {\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_warmup_steps': 1000,\n",
    "    'num_training_steps': len(batch_train) * epochs,\n",
    "    'max_grad_norm': 1\n",
    "}\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, output_hidden_states=True, output_attentions=True)\n",
    "model.to(device)\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=parameters['learning_rate'], correct_bias=False)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                                         num_warmup_steps=parameters['num_warmup_steps'],\n",
    "                                                         num_training_steps=parameters['num_training_steps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch):\n",
    "    input_ids, predictions, true_labels, attentions = [], [], [], []\n",
    "    model.eval()\n",
    "    for i, batch_cpu in enumerate(batch):\n",
    "        batch_gpu = (t.to(device) for t in batch_cpu)\n",
    "        input_ids_gpu, attention_mask, labels = batch_gpu\n",
    "        with torch.no_grad():\n",
    "            loss, logits, hidden_states_output, attention_mask_output = model(input_ids=input_ids_gpu, attention_mask=attention_mask, labels=labels)\n",
    "            logits =  logits.cpu()\n",
    "            prediction = torch.argmax(logits, dim=1).tolist()\n",
    "            true_label = labels.cpu().tolist()\n",
    "            input_ids_cpu = input_ids_gpu.cpu().tolist()\n",
    "            attention_last_layer = attention_mask_output[-1].cpu() # selection the last attention layer\n",
    "            attention_softmax = attention_last_layer[:,-1, 0].tolist()  # selection the last head attention of CLS token\n",
    "            input_ids += input_ids_cpu\n",
    "            predictions += prediction\n",
    "            true_labels += true_label\n",
    "            attentions += attention_softmax\n",
    "    return input_ids, predictions, true_labels, attentions\n",
    "\n",
    "def get_length_without_special_tokens(sentence):\n",
    "    length = 0\n",
    "    for i in sentence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        else:\n",
    "            length += 1\n",
    "    return length\n",
    "\n",
    "def print_attention(input_ids_all, attentions_all, tokenizer):\n",
    "    for input_ids, attention in zip(input_ids_all, attentions_all):\n",
    "        html = []\n",
    "        len_input_ids = get_length_without_special_tokens(input_ids)\n",
    "        input_ids = input_ids[:len_input_ids]\n",
    "        attention = attention[:len_input_ids]\n",
    "        for input_id, attention_value in zip(input_ids, attention):\n",
    "            token = tokenizer.convert_ids_to_tokens(input_id)\n",
    "            attention_value = attention_value\n",
    "            html.append('<span style=\"background-color: rgb(255,255,0,{0})\">{1}</span>'.format(10 * attention_value, token))\n",
    "        html_string = \" \".join(html)\n",
    "        display(HTML(html_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss - 0.7048430442810059\n",
      "loss - 0.6011022329330444\n",
      "loss - 0.3259471654891968\n",
      "loss - 0.09624850004911423\n",
      "loss - 0.33943769335746765\n",
      "loss - 0.1105036810040474\n",
      "loss - 0.013818517327308655\n",
      "loss - 0.45614898204803467\n",
      "loss - 0.2383934110403061\n"
     ]
    }
   ],
   "source": [
    "train_model(batch_train, model, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(batch_dev):\n",
    "    results = evaluate(batch_dev)\n",
    "    input_ids, predictions, true_labels, attentions = results\n",
    "    print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for Stanford treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       428\n",
      "           1       0.87      0.95      0.91       444\n",
      "\n",
      "    accuracy                           0.90       872\n",
      "   macro avg       0.90      0.90      0.90       872\n",
      "weighted avg       0.90      0.90      0.90       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(batch_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.15966447070240974)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.1695789210498333)\">at</span> <span style=\"background-color: rgb(255,255,0,0.3521907702088356)\">least</span> <span style=\"background-color: rgb(255,255,0,0.9564197063446045)\">one</span> <span style=\"background-color: rgb(255,255,0,0.8909577876329422)\">scene</span> <span style=\"background-color: rgb(255,255,0,1.078961193561554)\">is</span> <span style=\"background-color: rgb(255,255,0,0.19479777663946152)\">so</span> <span style=\"background-color: rgb(255,255,0,0.8683057129383087)\">disgusting</span> <span style=\"background-color: rgb(255,255,0,0.20176518708467484)\">that</span> <span style=\"background-color: rgb(255,255,0,0.2830309420824051)\">viewers</span> <span style=\"background-color: rgb(255,255,0,0.05265317391604185)\">may</span> <span style=\"background-color: rgb(255,255,0,0.09349959902465343)\">be</span> <span style=\"background-color: rgb(255,255,0,0.10218353010714054)\">hard</span> <span style=\"background-color: rgb(255,255,0,0.14339612796902657)\">pressed</span> <span style=\"background-color: rgb(255,255,0,0.07251916918903589)\">to</span> <span style=\"background-color: rgb(255,255,0,0.2534146048128605)\">retain</span> <span style=\"background-color: rgb(255,255,0,0.06161753088235855)\">their</span> <span style=\"background-color: rgb(255,255,0,0.636906772851944)\">lunch</span> <span style=\"background-color: rgb(255,255,0,1.7399808764457703)\">.</span> <span style=\"background-color: rgb(255,255,0,1.6881562769412994)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.28577443212270737)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.10224904865026474)\">a</span> <span style=\"background-color: rgb(255,255,0,0.09135874919593334)\">po</span> <span style=\"background-color: rgb(255,255,0,0.06475998554378748)\">##ignant</span> <span style=\"background-color: rgb(255,255,0,0.06788325496017933)\">and</span> <span style=\"background-color: rgb(255,255,0,0.05908642429858446)\">compelling</span> <span style=\"background-color: rgb(255,255,0,0.13064976781606674)\">story</span> <span style=\"background-color: rgb(255,255,0,0.19853409379720688)\">about</span> <span style=\"background-color: rgb(255,255,0,0.1480013970285654)\">relationships</span> <span style=\"background-color: rgb(255,255,0,0.098591148853302)\">,</span> <span style=\"background-color: rgb(255,255,0,0.18351374194025993)\">food</span> <span style=\"background-color: rgb(255,255,0,0.058537526056170464)\">of</span> <span style=\"background-color: rgb(255,255,0,0.05330410320311785)\">love</span> <span style=\"background-color: rgb(255,255,0,0.08618559688329697)\">takes</span> <span style=\"background-color: rgb(255,255,0,0.13388291001319885)\">us</span> <span style=\"background-color: rgb(255,255,0,0.08821365423500538)\">on</span> <span style=\"background-color: rgb(255,255,0,0.07342488970607519)\">a</span> <span style=\"background-color: rgb(255,255,0,0.8770293742418289)\">bump</span> <span style=\"background-color: rgb(255,255,0,0.09864192456007004)\">##y</span> <span style=\"background-color: rgb(255,255,0,0.3533979132771492)\">but</span> <span style=\"background-color: rgb(255,255,0,0.06756033282727003)\">satisfying</span> <span style=\"background-color: rgb(255,255,0,0.09098738431930542)\">journey</span> <span style=\"background-color: rgb(255,255,0,0.04450521431863308)\">of</span> <span style=\"background-color: rgb(255,255,0,0.0513837905600667)\">the</span> <span style=\"background-color: rgb(255,255,0,0.12285692617297173)\">heart</span> <span style=\"background-color: rgb(255,255,0,3.100994825363159)\">.</span> <span style=\"background-color: rgb(255,255,0,3.268691897392273)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.24877462536096573)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.12136409990489483)\">the</span> <span style=\"background-color: rgb(255,255,0,0.6669354438781738)\">film</span> <span style=\"background-color: rgb(255,255,0,0.035081347450613976)\">'</span> <span style=\"background-color: rgb(255,255,0,0.04754232242703438)\">s</span> <span style=\"background-color: rgb(255,255,0,0.09982071816921234)\">welcome</span> <span style=\"background-color: rgb(255,255,0,0.15577745623886585)\">bree</span> <span style=\"background-color: rgb(255,255,0,0.1687029004096985)\">##zine</span> <span style=\"background-color: rgb(255,255,0,0.16187630593776703)\">##ss</span> <span style=\"background-color: rgb(255,255,0,0.13367601670324802)\">and</span> <span style=\"background-color: rgb(255,255,0,0.15171085484325886)\">some</span> <span style=\"background-color: rgb(255,255,0,0.02519593108445406)\">un</span> <span style=\"background-color: rgb(255,255,0,0.03388859098777175)\">##bel</span> <span style=\"background-color: rgb(255,255,0,0.005499438848346472)\">##ie</span> <span style=\"background-color: rgb(255,255,0,0.016758758574724197)\">##va</span> <span style=\"background-color: rgb(255,255,0,0.031628243159502745)\">##bly</span> <span style=\"background-color: rgb(255,255,0,0.10705963708460331)\">hilarious</span> <span style=\"background-color: rgb(255,255,0,0.1443465519696474)\">moments</span> <span style=\"background-color: rgb(255,255,0,0.04463178105652332)\">-</span> <span style=\"background-color: rgb(255,255,0,0.07072489243000746)\">-</span> <span style=\"background-color: rgb(255,255,0,0.47310974448919296)\">most</span> <span style=\"background-color: rgb(255,255,0,0.5786601826548576)\">portraying</span> <span style=\"background-color: rgb(255,255,0,0.14989647082984447)\">the</span> <span style=\"background-color: rgb(255,255,0,0.34235991537570953)\">id</span> <span style=\"background-color: rgb(255,255,0,0.3002702631056309)\">##io</span> <span style=\"background-color: rgb(255,255,0,0.11242683045566082)\">##cy</span> <span style=\"background-color: rgb(255,255,0,0.14914428815245628)\">of</span> <span style=\"background-color: rgb(255,255,0,0.1570642925798893)\">the</span> <span style=\"background-color: rgb(255,255,0,0.24832798168063164)\">film</span> <span style=\"background-color: rgb(255,255,0,0.11775503866374493)\">industry</span> <span style=\"background-color: rgb(255,255,0,0.11403647251427174)\">-</span> <span style=\"background-color: rgb(255,255,0,0.1518480759114027)\">-</span> <span style=\"background-color: rgb(255,255,0,0.06408724933862686)\">make</span> <span style=\"background-color: rgb(255,255,0,0.10054574348032475)\">it</span> <span style=\"background-color: rgb(255,255,0,0.07746895309537649)\">mostly</span> <span style=\"background-color: rgb(255,255,0,0.09982037357985973)\">worth</span> <span style=\"background-color: rgb(255,255,0,0.06447046995162964)\">the</span> <span style=\"background-color: rgb(255,255,0,0.19654929637908936)\">trip</span> <span style=\"background-color: rgb(255,255,0,1.9863419234752655)\">.</span> <span style=\"background-color: rgb(255,255,0,2.044820785522461)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.8235964924097061)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,1.3206596672534943)\">scores</span> <span style=\"background-color: rgb(255,255,0,1.2423831969499588)\">no</span> <span style=\"background-color: rgb(255,255,0,1.9326125085353851)\">points</span> <span style=\"background-color: rgb(255,255,0,1.7910608649253845)\">for</span> <span style=\"background-color: rgb(255,255,0,0.012062026653438807)\">original</span> <span style=\"background-color: rgb(255,255,0,0.044139367528259754)\">##ity</span> <span style=\"background-color: rgb(255,255,0,0.18562108278274536)\">,</span> <span style=\"background-color: rgb(255,255,0,0.03515420947223902)\">wit</span> <span style=\"background-color: rgb(255,255,0,0.5101791769266129)\">,</span> <span style=\"background-color: rgb(255,255,0,0.690351203083992)\">or</span> <span style=\"background-color: rgb(255,255,0,0.01824070350266993)\">intelligence</span> <span style=\"background-color: rgb(255,255,0,0.9199965000152588)\">.</span> <span style=\"background-color: rgb(255,255,0,0.4739431291818619)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.08059438318014145)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.1013621874153614)\">li</span> <span style=\"background-color: rgb(255,255,0,0.24737823754549026)\">##ott</span> <span style=\"background-color: rgb(255,255,0,0.21770449355244637)\">##a</span> <span style=\"background-color: rgb(255,255,0,0.09382354095578194)\">put</span> <span style=\"background-color: rgb(255,255,0,0.10022048838436604)\">on</span> <span style=\"background-color: rgb(255,255,0,0.11172755621373653)\">30</span> <span style=\"background-color: rgb(255,255,0,0.4932967945933342)\">pounds</span> <span style=\"background-color: rgb(255,255,0,0.07564876694232225)\">for</span> <span style=\"background-color: rgb(255,255,0,0.08193495683372021)\">the</span> <span style=\"background-color: rgb(255,255,0,0.48974204808473587)\">role</span> <span style=\"background-color: rgb(255,255,0,1.6610877215862274)\">,</span> <span style=\"background-color: rgb(255,255,0,0.019233847269788384)\">and</span> <span style=\"background-color: rgb(255,255,0,0.018445116002112627)\">has</span> <span style=\"background-color: rgb(255,255,0,0.013197551015764475)\">completely</span> <span style=\"background-color: rgb(255,255,0,0.023460041265934706)\">transformed</span> <span style=\"background-color: rgb(255,255,0,0.11949330568313599)\">himself</span> <span style=\"background-color: rgb(255,255,0,0.8608584851026535)\">from</span> <span style=\"background-color: rgb(255,255,0,0.12029665522277355)\">his</span> <span style=\"background-color: rgb(255,255,0,0.7609653472900391)\">smooth</span> <span style=\"background-color: rgb(255,255,0,0.03513957839459181)\">,</span> <span style=\"background-color: rgb(255,255,0,0.19746219739317894)\">good</span> <span style=\"background-color: rgb(255,255,0,0.08446529507637024)\">##fell</span> <span style=\"background-color: rgb(255,255,0,0.20156696438789368)\">##as</span> <span style=\"background-color: rgb(255,255,0,0.15701035037636757)\">image</span> <span style=\"background-color: rgb(255,255,0,1.8196579813957214)\">.</span> <span style=\"background-color: rgb(255,255,0,1.8142268061637878)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.07089594379067421)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.029335906729102135)\">what</span> <span style=\"background-color: rgb(255,255,0,1.5199680626392365)\">'</span> <span style=\"background-color: rgb(255,255,0,0.010603847913444042)\">s</span> <span style=\"background-color: rgb(255,255,0,0.025528015103191137)\">surprising</span> <span style=\"background-color: rgb(255,255,0,0.03369371872395277)\">about</span> <span style=\"background-color: rgb(255,255,0,0.05916649475693703)\">full</span> <span style=\"background-color: rgb(255,255,0,0.07706474047154188)\">frontal</span> <span style=\"background-color: rgb(255,255,0,0.01324446639046073)\">is</span> <span style=\"background-color: rgb(255,255,0,0.013775121187791228)\">that</span> <span style=\"background-color: rgb(255,255,0,0.4825354740023613)\">despite</span> <span style=\"background-color: rgb(255,255,0,0.0817412044852972)\">its</span> <span style=\"background-color: rgb(255,255,0,0.08198205381631851)\">over</span> <span style=\"background-color: rgb(255,255,0,0.03847446525469422)\">##t</span> <span style=\"background-color: rgb(255,255,0,0.07298431359231472)\">self</span> <span style=\"background-color: rgb(255,255,0,0.016485844971612096)\">-</span> <span style=\"background-color: rgb(255,255,0,0.14729969203472137)\">awareness</span> <span style=\"background-color: rgb(255,255,0,1.6221272945404053)\">,</span> <span style=\"background-color: rgb(255,255,0,0.22954825311899185)\">parts</span> <span style=\"background-color: rgb(255,255,0,0.07071924395859241)\">of</span> <span style=\"background-color: rgb(255,255,0,0.06519542075693607)\">the</span> <span style=\"background-color: rgb(255,255,0,0.44285792857408524)\">movie</span> <span style=\"background-color: rgb(255,255,0,0.051875789649784565)\">still</span> <span style=\"background-color: rgb(255,255,0,0.028895558789372444)\">manage</span> <span style=\"background-color: rgb(255,255,0,0.022006987128406763)\">to</span> <span style=\"background-color: rgb(255,255,0,0.1337236724793911)\">break</span> <span style=\"background-color: rgb(255,255,0,0.38066379725933075)\">past</span> <span style=\"background-color: rgb(255,255,0,0.06962312385439873)\">the</span> <span style=\"background-color: rgb(255,255,0,0.03884827019646764)\">art</span> <span style=\"background-color: rgb(255,255,0,0.1760265976190567)\">##ifice</span> <span style=\"background-color: rgb(255,255,0,0.05730566568672657)\">and</span> <span style=\"background-color: rgb(255,255,0,0.022238448727875948)\">thoroughly</span> <span style=\"background-color: rgb(255,255,0,0.05130867939442396)\">engage</span> <span style=\"background-color: rgb(255,255,0,0.3010857291519642)\">you</span> <span style=\"background-color: rgb(255,255,0,1.780501902103424)\">.</span> <span style=\"background-color: rgb(255,255,0,1.680668294429779)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.8963032811880112)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,1.2057743221521378)\">as</span> <span style=\"background-color: rgb(255,255,0,1.613011658191681)\">vulgar</span> <span style=\"background-color: rgb(255,255,0,0.8069944381713867)\">as</span> <span style=\"background-color: rgb(255,255,0,1.171400547027588)\">it</span> <span style=\"background-color: rgb(255,255,0,0.27770597487688065)\">is</span> <span style=\"background-color: rgb(255,255,0,0.48376675695180893)\">ban</span> <span style=\"background-color: rgb(255,255,0,0.5839471891522408)\">##al</span> <span style=\"background-color: rgb(255,255,0,1.0227708518505096)\">.</span> <span style=\"background-color: rgb(255,255,0,1.9383253157138824)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.5823197588324547)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,4.384237825870514)\">instead</span> <span style=\"background-color: rgb(255,255,0,1.169663667678833)\">,</span> <span style=\"background-color: rgb(255,255,0,0.09700478054583073)\">he</span> <span style=\"background-color: rgb(255,255,0,0.06386173889040947)\">shows</span> <span style=\"background-color: rgb(255,255,0,0.3574700281023979)\">them</span> <span style=\"background-color: rgb(255,255,0,0.018996489234268665)\">the</span> <span style=\"background-color: rgb(255,255,0,0.15267937444150448)\">respect</span> <span style=\"background-color: rgb(255,255,0,0.03700583940371871)\">they</span> <span style=\"background-color: rgb(255,255,0,0.039702700451016426)\">are</span> <span style=\"background-color: rgb(255,255,0,0.12541630305349827)\">due</span> <span style=\"background-color: rgb(255,255,0,1.4915597438812256)\">.</span> <span style=\"background-color: rgb(255,255,0,1.4800822734832764)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.11511445976793766)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.020026068668812513)\">so</span> <span style=\"background-color: rgb(255,255,0,0.008621421875432134)\">,</span> <span style=\"background-color: rgb(255,255,0,0.09279975667595863)\">too</span> <span style=\"background-color: rgb(255,255,0,0.783807635307312)\">,</span> <span style=\"background-color: rgb(255,255,0,0.5341146513819695)\">is</span> <span style=\"background-color: rgb(255,255,0,0.7086607068777084)\">this</span> <span style=\"background-color: rgb(255,255,0,1.4820529520511627)\">comedy</span> <span style=\"background-color: rgb(255,255,0,0.9455318003892899)\">about</span> <span style=\"background-color: rgb(255,255,0,0.7040582597255707)\">mild</span> <span style=\"background-color: rgb(255,255,0,0.7888446003198624)\">culture</span> <span style=\"background-color: rgb(255,255,0,0.6344630569219589)\">clash</span> <span style=\"background-color: rgb(255,255,0,0.14328313060104847)\">##ing</span> <span style=\"background-color: rgb(255,255,0,0.23308506235480309)\">in</span> <span style=\"background-color: rgb(255,255,0,0.5169962346553802)\">today</span> <span style=\"background-color: rgb(255,255,0,0.036882509011775255)\">'</span> <span style=\"background-color: rgb(255,255,0,0.06538859102874994)\">s</span> <span style=\"background-color: rgb(255,255,0,0.07281318306922913)\">new</span> <span style=\"background-color: rgb(255,255,0,0.45522473752498627)\">delhi</span> <span style=\"background-color: rgb(255,255,0,0.8397001028060913)\">.</span> <span style=\"background-color: rgb(255,255,0,0.8185310661792755)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255,255,0,0.18981726840138435)\">[CLS]</span> <span style=\"background-color: rgb(255,255,0,0.07672667037695646)\">something</span> <span style=\"background-color: rgb(255,255,0,0.07574314717203379)\">akin</span> <span style=\"background-color: rgb(255,255,0,0.10492684319615364)\">to</span> <span style=\"background-color: rgb(255,255,0,0.6521875411272049)\">a</span> <span style=\"background-color: rgb(255,255,0,0.7265853881835938)\">japanese</span> <span style=\"background-color: rgb(255,255,0,0.7306437939405441)\">alice</span> <span style=\"background-color: rgb(255,255,0,0.18032407388091087)\">through</span> <span style=\"background-color: rgb(255,255,0,0.09361530654132366)\">the</span> <span style=\"background-color: rgb(255,255,0,0.08508953265845776)\">looking</span> <span style=\"background-color: rgb(255,255,0,0.05470127332955599)\">glass</span> <span style=\"background-color: rgb(255,255,0,1.358770728111267)\">,</span> <span style=\"background-color: rgb(255,255,0,0.05306510254740715)\">except</span> <span style=\"background-color: rgb(255,255,0,0.034676180221140385)\">that</span> <span style=\"background-color: rgb(255,255,0,0.3419587016105652)\">it</span> <span style=\"background-color: rgb(255,255,0,0.1251821592450142)\">seems</span> <span style=\"background-color: rgb(255,255,0,0.11079560965299606)\">to</span> <span style=\"background-color: rgb(255,255,0,0.2920619584619999)\">take</span> <span style=\"background-color: rgb(255,255,0,0.29828229919075966)\">itself</span> <span style=\"background-color: rgb(255,255,0,0.14150211587548256)\">far</span> <span style=\"background-color: rgb(255,255,0,0.3167339786887169)\">more</span> <span style=\"background-color: rgb(255,255,0,0.9669549763202667)\">seriously</span> <span style=\"background-color: rgb(255,255,0,1.5264604985713959)\">.</span> <span style=\"background-color: rgb(255,255,0,1.4631949365139008)\">[SEP]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a8752a30635a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-cf2aa731299c>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    output_dir = './output'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    print(\"Saving model to {}\".format(output_dir))\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to {0} ./outputs_reddit_lr=2e-05_epochs=2\n"
     ]
    }
   ],
   "source": [
    "save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
